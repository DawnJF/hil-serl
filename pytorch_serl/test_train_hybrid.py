"""æ··åˆæ¨¡å¼è®­ç»ƒæµ‹è¯•è„šæœ¬"""

import os
import sys
import torch
import numpy as np
import pickle as pkl
import tempfile
import shutil
import threading
import time
from unittest.mock import MagicMock, patch

sys.path.append(".")

from train_hybrid import (
    train_hybrid,
    SharedReplayBuffer,
    MockEnvironment,
    actor_loop,
    learner_loop,
    concat_batches,
)
from agents.sac import SACHybridAgent
from utils.device import DEVICE


class TestHybridTraining:
    """æ··åˆè®­ç»ƒæµ‹è¯•ç±»"""

    def __init__(self):
        self.test_dir: str = ""
        self.demo_paths = []

    def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        print("è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")

        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.test_dir = tempfile.mkdtemp(prefix="test_hybrid_")
        print(f"æµ‹è¯•ç›®å½•: {self.test_dir}")

        # ç”Ÿæˆæµ‹è¯•æ¼”ç¤ºæ•°æ®
        self.generate_test_demos()

    def cleanup_test_environment(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        if self.test_dir and os.path.exists(self.test_dir):
            shutil.rmtree(self.test_dir)
            print(f"æ¸…ç†æµ‹è¯•ç›®å½•: {self.test_dir}")

    def generate_test_demos(self):
        """ç”Ÿæˆæµ‹è¯•æ¼”ç¤ºæ•°æ®"""
        print("ç”Ÿæˆæµ‹è¯•æ¼”ç¤ºæ•°æ®...")

        # ç”ŸæˆæˆåŠŸæ¼”ç¤º
        success_data = []
        for i in range(50):
            transition = {
                "observations": {
                    "image": np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)
                },
                "actions": np.random.uniform(-1, 1, 7),
                "next_observations": {
                    "image": np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)
                },
                "rewards": np.random.uniform(0.8, 1.0),  # é«˜å¥–åŠ±
                "masks": 1.0,
                "dones": np.random.choice([True, False], p=[0.1, 0.9]),
            }
            success_data.append(transition)

        success_path = os.path.join(self.test_dir, "success_demo.pkl")
        with open(success_path, "wb") as f:
            pkl.dump(success_data, f)

        # ç”Ÿæˆä¸€èˆ¬æ¼”ç¤º
        mixed_data = []
        for i in range(30):
            transition = {
                "observations": {
                    "image": np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)
                },
                "actions": np.random.uniform(-1, 1, 7),
                "next_observations": {
                    "image": np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)
                },
                "rewards": np.random.uniform(-0.5, 0.8),  # æ··åˆå¥–åŠ±
                "masks": 1.0,
                "dones": np.random.choice([True, False], p=[0.2, 0.8]),
            }
            mixed_data.append(transition)

        mixed_path = os.path.join(self.test_dir, "mixed_demo.pkl")
        with open(mixed_path, "wb") as f:
            pkl.dump(mixed_data, f)

        self.demo_paths = [success_path, mixed_path]
        print(
            f"ç”Ÿæˆæ¼”ç¤ºæ•°æ®: {len(success_data)} æˆåŠŸæ ·æœ¬ + {len(mixed_data)} æ··åˆæ ·æœ¬"
        )

    def test_shared_replay_buffer(self):
        """æµ‹è¯•å…±äº«é‡æ”¾ç¼“å†²åŒº"""
        print("\n=== æµ‹è¯•å…±äº«é‡æ”¾ç¼“å†²åŒº ===")

        image_keys = ["image"]
        buffer = SharedReplayBuffer(capacity=1000, image_keys=image_keys)

        # æµ‹è¯•æ’å…¥
        for i in range(10):
            transition = {
                "observations": {
                    "image": np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)
                },
                "actions": np.random.randn(7),
                "next_observations": {
                    "image": np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)
                },
                "rewards": np.random.randn(),
                "masks": 1.0,
                "dones": False,
            }
            buffer.insert(transition)

        print(f"ç¼“å†²åŒºå¤§å°: {len(buffer)}")

        # æµ‹è¯•é‡‡æ ·
        batch = buffer.sample(batch_size=5, device=DEVICE)
        if batch is not None:
            print(f"é‡‡æ ·æˆåŠŸï¼Œæ‰¹æ¬¡å¤§å°: {batch['actions'].shape[0]}")
        else:
            print("é‡‡æ ·å¤±è´¥ï¼Œæ•°æ®ä¸è¶³")

        # æµ‹è¯•çº¿ç¨‹å®‰å…¨
        def insert_worker():
            for i in range(5):
                transition = {
                    "observations": {
                        "image": np.random.randint(
                            0, 255, (128, 128, 3), dtype=np.uint8
                        )
                    },
                    "actions": np.random.randn(7),
                    "next_observations": {
                        "image": np.random.randint(
                            0, 255, (128, 128, 3), dtype=np.uint8
                        )
                    },
                    "rewards": np.random.randn(),
                    "masks": 1.0,
                    "dones": False,
                }
                buffer.insert(transition)

        threads = [threading.Thread(target=insert_worker) for _ in range(3)]
        for t in threads:
            t.start()
        for t in threads:
            t.join()

        print(f"å¤šçº¿ç¨‹æ’å…¥åç¼“å†²åŒºå¤§å°: {len(buffer)}")
        return True

    def test_mock_environment(self):
        """æµ‹è¯•æ¨¡æ‹Ÿç¯å¢ƒ"""
        print("\n=== æµ‹è¯•æ¨¡æ‹Ÿç¯å¢ƒ ===")

        image_keys = ["image"]
        action_dim = 7
        env = MockEnvironment(image_keys, action_dim)

        # æµ‹è¯•é‡ç½®
        obs, info = env.reset()
        print(f"é‡ç½®è§‚æµ‹é”®: {list(obs.keys())}")
        print(f"å›¾åƒå½¢çŠ¶: {obs['image'].shape}")

        # æµ‹è¯•æ­¥è¿›
        action = np.random.uniform(-1, 1, action_dim)
        next_obs, reward, done, truncated, info = env.step(action)

        print(f"æ­¥è¿›ç»“æœ: reward={reward:.3f}, done={done}, truncated={truncated}")
        print(f"ä¿¡æ¯é”®: {list(info.keys())}")

        # æµ‹è¯•äººå·¥å¹²é¢„
        intervention_count = 0
        for _ in range(100):
            action = np.random.uniform(-1, 1, action_dim)
            next_obs, reward, done, truncated, info = env.step(action)
            if "intervene_action" in info:
                intervention_count += 1

        print(f"100æ­¥ä¸­äººå·¥å¹²é¢„æ¬¡æ•°: {intervention_count}")
        return True

    def test_concat_batches(self):
        """æµ‹è¯•æ‰¹æ¬¡åˆå¹¶"""
        print("\n=== æµ‹è¯•æ‰¹æ¬¡åˆå¹¶ ===")

        # åˆ›å»ºæµ‹è¯•æ‰¹æ¬¡
        batch1 = {
            "observations": {"image": torch.randn(4, 3, 128, 128).to(DEVICE)},
            "actions": torch.randn(4, 7).to(DEVICE),
            "rewards": torch.randn(4, 1).to(DEVICE),
        }

        batch2 = {
            "observations": {"image": torch.randn(4, 3, 128, 128).to(DEVICE)},
            "actions": torch.randn(4, 7).to(DEVICE),
            "rewards": torch.randn(4, 1).to(DEVICE),
        }

        # åˆå¹¶æ‰¹æ¬¡
        merged = concat_batches(batch1, batch2)

        print(f"åˆå¹¶å‰æ‰¹æ¬¡1å¤§å°: {batch1['actions'].shape[0]}")
        print(f"åˆå¹¶å‰æ‰¹æ¬¡2å¤§å°: {batch2['actions'].shape[0]}")
        print(f"åˆå¹¶åæ‰¹æ¬¡å¤§å°: {merged['actions'].shape[0]}")

        # éªŒè¯åˆå¹¶ç»“æœ
        expected_size = batch1["actions"].shape[0] + batch2["actions"].shape[0]
        assert (
            merged["actions"].shape[0] == expected_size
        ), f"åˆå¹¶å¤§å°ä¸åŒ¹é…: {merged['actions'].shape[0]} != {expected_size}"

        return True

    def test_agent_creation(self):
        """æµ‹è¯•æ™ºèƒ½ä½“åˆ›å»º"""
        print("\n=== æµ‹è¯•æ™ºèƒ½ä½“åˆ›å»º ===")

        image_keys = ["image"]

        # åˆ›å»ºæ··åˆSACæ™ºèƒ½ä½“
        agent = SACHybridAgent(
            image_keys=image_keys,
            continuous_action_dim=6,
            grasp_action_dim=3,
            lr=3e-4,
            device=DEVICE,
        )

        print(f"æ™ºèƒ½ä½“è®¾å¤‡: {agent.device}")
        print(f"æ™ºèƒ½ä½“å›¾åƒé”®: {agent.image_keys}")

        # æµ‹è¯•åŠ¨ä½œé‡‡æ ·
        test_obs = {"image": torch.randn(2, 3, 128, 128).to(DEVICE)}

        actions = agent.sample_actions(test_obs, deterministic=False)
        print(f"åŠ¨ä½œå½¢çŠ¶: {actions.shape}")

        # æµ‹è¯•ç¡®å®šæ€§åŠ¨ä½œ
        det_actions = agent.sample_actions(test_obs, deterministic=True)
        print(f"ç¡®å®šæ€§åŠ¨ä½œå½¢çŠ¶: {det_actions.shape}")

        return True

    def test_short_training_run(self):
        """æµ‹è¯•çŸ­æ—¶é—´è®­ç»ƒè¿è¡Œ"""
        print("\n=== æµ‹è¯•çŸ­æ—¶é—´è®­ç»ƒè¿è¡Œ ===")

        save_dir = os.path.join(self.test_dir, "test_hybrid_ckpt")

        try:
            # è¿è¡ŒçŸ­æ—¶é—´è®­ç»ƒ
            agent = train_hybrid(
                demo_paths=self.demo_paths,
                image_keys=["image"],
                setup_mode="single-arm-fixed-gripper",
                max_steps=500,  # çŸ­æ—¶é—´è®­ç»ƒ
                batch_size=32,  # å°æ‰¹æ¬¡
                lr=3e-4,
                training_starts=50,  # å‡å°‘å¯åŠ¨é˜ˆå€¼
                random_steps=100,  # å‡å°‘éšæœºæ­¥æ•°
                cta_ratio=2,
                save_dir=save_dir,
                log_interval=50,
            )

            print(f"è®­ç»ƒå®Œæˆï¼Œæ™ºèƒ½ä½“ç±»å‹: {type(agent)}")

            # æ£€æŸ¥ä¿å­˜çš„æ–‡ä»¶
            if os.path.exists(save_dir):
                saved_files = os.listdir(save_dir)
                print(f"ä¿å­˜çš„æ–‡ä»¶: {saved_files}")

                # éªŒè¯æœ€ç»ˆæ¨¡å‹æ˜¯å¦å­˜åœ¨
                final_model_path = os.path.join(save_dir, "final_model.pth")
                if os.path.exists(final_model_path):
                    print("âœ… æœ€ç»ˆæ¨¡å‹ä¿å­˜æˆåŠŸ")
                else:
                    print("âŒ æœ€ç»ˆæ¨¡å‹ä¿å­˜å¤±è´¥")

            return True

        except Exception as e:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
            import traceback

            traceback.print_exc()
            return False

    def test_actor_loop_isolated(self):
        """æµ‹è¯•ç‹¬ç«‹çš„æ¼”å‘˜å¾ªç¯"""
        print("\n=== æµ‹è¯•ç‹¬ç«‹æ¼”å‘˜å¾ªç¯ ===")

        # åˆ›å»ºæµ‹è¯•ç»„ä»¶
        image_keys = ["image"]
        action_dim = 7

        agent = SACHybridAgent(
            image_keys=image_keys,
            continuous_action_dim=6,
            grasp_action_dim=3,
            device=DEVICE,
        )
        setattr(agent, "action_dim", action_dim)

        env = MockEnvironment(image_keys, action_dim)
        replay_buffer = SharedReplayBuffer(capacity=1000, image_keys=image_keys)
        demo_buffer = SharedReplayBuffer(capacity=1000, image_keys=image_keys)

        # è¿è¡ŒçŸ­æ—¶é—´æ¼”å‘˜å¾ªç¯
        print("è¿è¡Œæ¼”å‘˜å¾ªç¯...")

        def run_actor():
            actor_loop(
                agent=agent,
                env=env,
                replay_buffer=replay_buffer,
                demo_buffer=demo_buffer,
                max_steps=100,
                random_steps=50,
                update_queue=None,
            )

        actor_thread = threading.Thread(target=run_actor)
        actor_thread.start()
        actor_thread.join(timeout=30)  # 30ç§’è¶…æ—¶

        print(f"æ¼”å‘˜å¾ªç¯å®Œæˆï¼Œé‡æ”¾ç¼“å†²åŒºå¤§å°: {len(replay_buffer)}")
        print(f"æ¼”ç¤ºç¼“å†²åŒºå¤§å°: {len(demo_buffer)}")

        return len(replay_buffer) > 0

    def test_learner_loop_isolated(self):
        """æµ‹è¯•ç‹¬ç«‹çš„å­¦ä¹ è€…å¾ªç¯"""
        print("\n=== æµ‹è¯•ç‹¬ç«‹å­¦ä¹ è€…å¾ªç¯ ===")

        # åˆ›å»ºæµ‹è¯•ç»„ä»¶
        image_keys = ["image"]

        agent = SACHybridAgent(
            image_keys=image_keys,
            continuous_action_dim=6,
            grasp_action_dim=3,
            device=DEVICE,
        )

        replay_buffer = SharedReplayBuffer(capacity=1000, image_keys=image_keys)
        demo_buffer = SharedReplayBuffer(capacity=1000, image_keys=image_keys)

        # é¢„å¡«å……ä¸€äº›æ•°æ®
        for i in range(100):
            transition = {
                "observations": {
                    "image": np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)
                },
                "actions": np.random.uniform(-1, 1, 7),
                "next_observations": {
                    "image": np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)
                },
                "rewards": np.random.randn(),
                "masks": 1.0,
                "dones": False,
            }
            replay_buffer.insert(transition)
            if i < 50:  # ä¸€åŠæ•°æ®ä¹ŸåŠ åˆ°æ¼”ç¤ºç¼“å†²åŒº
                demo_buffer.insert(transition)

        print(
            f"é¢„å¡«å……æ•°æ® - é‡æ”¾ç¼“å†²åŒº: {len(replay_buffer)}, æ¼”ç¤ºç¼“å†²åŒº: {len(demo_buffer)}"
        )

        # è¿è¡ŒçŸ­æ—¶é—´å­¦ä¹ è€…å¾ªç¯
        save_dir = os.path.join(self.test_dir, "test_learner_ckpt")

        def run_learner():
            learner_loop(
                agent=agent,
                replay_buffer=replay_buffer,
                demo_buffer=demo_buffer,
                max_steps=100,
                batch_size=16,
                training_starts=50,
                cta_ratio=2,
                log_interval=25,
                save_dir=save_dir,
                update_queue=None,
            )

        learner_thread = threading.Thread(target=run_learner)
        learner_thread.start()
        learner_thread.join(timeout=60)  # 60ç§’è¶…æ—¶

        print("å­¦ä¹ è€…å¾ªç¯å®Œæˆ")

        # æ£€æŸ¥ä¿å­˜çš„æ–‡ä»¶
        if os.path.exists(save_dir):
            saved_files = os.listdir(save_dir)
            print(f"ä¿å­˜çš„æ–‡ä»¶: {saved_files}")
            return len(saved_files) > 0

        return False

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("=== æ··åˆæ¨¡å¼è®­ç»ƒæµ‹è¯•å¥—ä»¶ ===")

        test_results = {}

        try:
            self.setup_test_environment()

            # åŸºç¡€ç»„ä»¶æµ‹è¯•
            test_results["shared_replay_buffer"] = self.test_shared_replay_buffer()
            test_results["mock_environment"] = self.test_mock_environment()
            test_results["concat_batches"] = self.test_concat_batches()
            test_results["agent_creation"] = self.test_agent_creation()

            # ç‹¬ç«‹ç»„ä»¶æµ‹è¯•
            test_results["actor_loop"] = self.test_actor_loop_isolated()
            test_results["learner_loop"] = self.test_learner_loop_isolated()

            # å®Œæ•´è®­ç»ƒæµ‹è¯•
            test_results["short_training"] = self.test_short_training_run()

        except Exception as e:
            print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback

            traceback.print_exc()
            test_results["error"] = str(e)

        finally:
            self.cleanup_test_environment()

        # è¾“å‡ºæµ‹è¯•ç»“æœ
        print("\n=== æµ‹è¯•ç»“æœæ±‡æ€» ===")
        passed = 0
        total = 0

        for test_name, result in test_results.items():
            if test_name == "error":
                continue
            total += 1
            if result:
                print(f"âœ… {test_name}: é€šè¿‡")
                passed += 1
            else:
                print(f"âŒ {test_name}: å¤±è´¥")

        print(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")

        if "error" in test_results:
            print(f"é”™è¯¯ä¿¡æ¯: {test_results['error']}")

        return passed == total and "error" not in test_results


def test_performance_metrics():
    """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡"""
    print("\n=== æ€§èƒ½æµ‹è¯• ===")

    # æµ‹è¯•æ•°æ®åŠ è½½æ€§èƒ½
    print("æµ‹è¯•æ•°æ®åŠ è½½æ€§èƒ½...")
    start_time = time.time()

    # ç”Ÿæˆå¤§é‡æµ‹è¯•æ•°æ®
    test_data = []
    for i in range(1000):
        transition = {
            "observations": {
                "image": np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)
            },
            "actions": np.random.uniform(-1, 1, 7),
            "next_observations": {
                "image": np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)
            },
            "rewards": np.random.randn(),
            "masks": 1.0,
            "dones": False,
        }
        test_data.append(transition)

    data_gen_time = time.time() - start_time
    print(f"ç”Ÿæˆ1000ä¸ªè½¬æ¢è€—æ—¶: {data_gen_time:.2f}ç§’")

    # æµ‹è¯•ç¼“å†²åŒºæ’å…¥æ€§èƒ½
    print("æµ‹è¯•ç¼“å†²åŒºæ’å…¥æ€§èƒ½...")
    buffer = SharedReplayBuffer(capacity=10000, image_keys=["image"])

    start_time = time.time()
    for transition in test_data:
        buffer.insert(transition)
    insert_time = time.time() - start_time
    print(f"æ’å…¥1000ä¸ªè½¬æ¢è€—æ—¶: {insert_time:.2f}ç§’")

    # æµ‹è¯•é‡‡æ ·æ€§èƒ½
    print("æµ‹è¯•é‡‡æ ·æ€§èƒ½...")
    start_time = time.time()
    for _ in range(100):
        batch = buffer.sample(batch_size=32, device=DEVICE)
    sample_time = time.time() - start_time
    print(f"é‡‡æ ·100æ¬¡(æ¯æ¬¡32ä¸ªæ ·æœ¬)è€—æ—¶: {sample_time:.2f}ç§’")

    return True


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æ··åˆæ¨¡å¼è®­ç»ƒæµ‹è¯•...")

    # åŸºç¡€ç¯å¢ƒæ£€æŸ¥
    print(f"ä½¿ç”¨è®¾å¤‡: {DEVICE}")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")

    # è¿è¡Œä¸»è¦æµ‹è¯•
    tester = TestHybridTraining()
    success = tester.run_all_tests()

    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    test_performance_metrics()

    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ··åˆæ¨¡å¼è®­ç»ƒå®ç°æ­£ç¡®ã€‚")
        print("\nå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œå®Œæ•´è®­ç»ƒ:")
        print(
            "python train_hybrid.py --demo_paths test_data/success_demo.pkl --max_steps 10000"
        )
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
